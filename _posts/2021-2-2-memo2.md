---
title: Outlier vs Anomaly
description: Memo
categories:
 - Memo
tags: DataScience Statistics
---

A tongue-in-cheek answer:

Outlier: a value that you predictably find in your data that indicates your model does not work properly

Anomaly: a value that against all odds you find in your data that indicates your model does work properly

A more serious, less cryptic answer:

The concept of outliers starts from the issue of building a model that makes assumptions about the data. Outliers are often indicators that the model does not describe the data properly and thus we should question the results of our model or quality of our data.

The concept of anomalies starts outside the theoretic world and inside the applied world: we want to look for unusual behavior in our data, sometimes motivated by the fact that we are interested in finding behavior that someone is trying to hide (like a virus in an email). The problem is that since people are trying to hide what they are doing, we don't really know what to look for. So we take a set of "good" data, and decide that whatever we find in our new dataset that doesn't look "good" is an anomaly and worth our time to checkout in more detail. Often, looking for anomalies means looking for outliers in your new data set. But note that these values may be very common in your new dataset, despite being rare in your old dataset!

In summary, the two concepts are very similar in terms of the statistics behind them (i.e. unusual values given your fitted model) but come at the idea from different angles. In addition, when we talk about outliers, we typically mean an unusual data point in the data used to fit our model, where as an anomaly is usually meant as an unusual data point in a dataset outside of the data used to fit our model.

Note: this answer is based on how I've seen the two terms frequently used rather than formal definitions. User experiences may differ.
